FROM ac2-registry.cn-hangzhou.cr.aliyuncs.com/ac2/base:ubuntu22.04

RUN apt-get update && \
    apt-get install -y openjdk-8-jdk wget openssh-server vim


RUN mkdir /var/run/sshd && \
    ssh-keygen -t rsa -P '' -f /root/.ssh/id_rsa && \
    cat /root/.ssh/id_rsa.pub >> /root/.ssh/authorized_keys && \
    chmod 600 /root/.ssh/authorized_keys && \
    sed -i 's/#PasswordAuthentication yes/PasswordAuthentication no/' /etc/ssh/sshd_config && \
    sed -i 's/#PubkeyAuthentication yes/PubkeyAuthentication yes/' /etc/ssh/sshd_config && \
    sed -i 's@#AuthorizedKeysFile.*@AuthorizedKeysFile .ssh/authorized_keys@' /etc/ssh/sshd_config


ENV JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64
ENV PATH $JAVA_HOME/bin:$PATH
    
ENV HDFS_DATANODE_USER root 
ENV HDFS_DATANODE_SECURE_USER hdfs
ENV HDFS_NAMENODE_USER root
ENV HDFS_SECONDARYNAMENODE_USER root
ENV YARN_RESOURCEMANAGER_USER root
ENV HADOOP_SECURE_DN_USER yarn
ENV YARN_NODEMANAGER_USER root


RUN echo "export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64" >> /etc/profile
RUN echo "export JRE_HOME=$JAVA_HOME/jre" >> /etc/profile
RUN echo "export CLASSPATH=$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH" >> /etc/profile
RUN echo "export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH" >> /etc/profile
# RUN source /etc/profile

# 设置环境变量
ENV HADOOP_VERSION 3.3.6
ENV HADOOP_HOME /opt/hadoop-$HADOOP_VERSION
ENV PATH $PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

# 下载并解压Hadoop
RUN wget https://downloads.apache.org/hadoop/common/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz \
   && tar -xzf hadoop-$HADOOP_VERSION.tar.gz -C /opt \
   && rm hadoop-$HADOOP_VERSION.tar.gz
# COPY hadoop-3.3.6.tar.gz hadoop-3.3.6.tar.gz
# RUN tar -xzf hadoop-3.3.6.tar.gz -C /opt && rm hadoop-3.3.6.tar.gz

RUN echo "JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64" >> tmpfile
RUN echo "HDFS_DATANODE_USER=root" >> tmpfile
RUN echo "HDFS_DATANODE_SECURE_USER=hdfs" >> tmpfile
RUN echo "HDFS_NAMENODE_USER=root" >> tmpfile
RUN echo "HDFS_SECONDARYNAMENODE_USER=root" >> tmpfile
RUN cp tmpfile tmpfile1
RUN cat /opt/hadoop-3.3.6/sbin/start-dfs.sh >> tmpfile1 && cp tmpfile1 /opt/hadoop-3.3.6/sbin/start-dfs.sh && rm tmpfile1
RUN cat /opt/hadoop-3.3.6/sbin/stop-dfs.sh >> tmpfile && cp tmpfile /opt/hadoop-3.3.6/sbin/stop-dfs.sh && rm tmpfile
RUN echo "JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64" >> tmpfile
RUN echo "YARN_RESOURCEMANAGER_USER=root" >> tmpfile
RUN echo "HADOOP_SECURE_DN_USER=yarn" >> tmpfile
RUN echo "YARN_NODEMANAGER_USER=root" >> tmpfile
RUN cp tmpfile tmpfile1
RUN cat /opt/hadoop-3.3.6/sbin/start-yarn.sh >> tmpfile1 && cp tmpfile1 /opt/hadoop-3.3.6/sbin/start-yarn.sh && rm tmpfile1
RUN cat /opt/hadoop-3.3.6/sbin/stop-yarn.sh >> tmpfile && cp tmpfile /opt/hadoop-3.3.6/sbin/stop-yarn.sh && rm tmpfile
RUN echo "export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64" >> $HADOOP_HOME/etc/hadoop/hadoop-env.sh


# 复制配置文件到容器中
COPY core-site.xml $HADOOP_HOME/etc/hadoop/core-site.xml
COPY hdfs-site.xml $HADOOP_HOME/etc/hadoop/hdfs-site.xml
COPY mapred-site.xml $HADOOP_HOME/etc/hadoop/mapred-site.xml
COPY yarn-site.xml $HADOOP_HOME/etc/hadoop/yarn-site.xml
COPY workers $HADOOP_HOME/etc/hadoop/workers

# 暴露Hadoop和Spark的端口
EXPOSE 9870 9000 8088 7077 8080 18080 9864 22 10020 19888

COPY entrypoint.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh

# 启动脚本
CMD ["/entrypoint.sh"]