version: '3.8'

services:
  namenode:
    build: ./hadoop
    container_name: namenode
    ports:
      - "9870:9870"
      - "2222:22"
      - "19888:19888"
      - "8088:8088"
    volumes:
      - namenode-data:/usr/local/hadoop-3.3.6/tmp/namenode
    environment:
      - CLUSTER_NAME=myhadoop
    networks:
      hadoop-net:
        ipv4_address: 172.25.0.2
    tty: true
    deploy:
      resources:
        limits:
          memory: 16G
    

  datanode1:
    build: ./hadoop
    container_name: datanode1
    depends_on:
      - namenode
    ports:
      - "2223:22"
    volumes:
      - datanode1-data:/usr/local/hadoop-3.3.6/tmp/datanode
    environment:
      - CLUSTER_NAME=myhadoop
      - NAMENODE_SERVICE_HOST=namenode
    networks:
      hadoop-net:
        ipv4_address: 172.25.0.3
    tty: true
    deploy:
      resources:
        limits:
          memory: 16G

  datanode2:
    build: ./hadoop
    container_name: datanode2
    depends_on:
      - namenode
    ports:
      - "2224:22"
    volumes:
      - datanode2-data:/usr/local/hadoop-3.3.6/tmp/datanode
    environment:
      - CLUSTER_NAME=myhadoop
      - NAMENODE_SERVICE_HOST=namenode
    networks:
      hadoop-net:
        ipv4_address: 172.25.0.4
    tty: true
    deploy:
      resources:
        limits:
          memory: 16G

  spark-master:
    build: ./spark
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
      - "6066:6066"
      - "2225:22"
      - "18080:18080"
    environment:
      - SPARK_MODE=master
    networks:
      hadoop-net:
        ipv4_address: 172.25.0.5
    tty: true
    deploy:
      resources:
        limits:
          memory: 16G


  spark-worker-1:
    build: ./spark
    container_name: spark-worker-1
    ports:
      - "8081:8081"
      - "2226:22"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
    networks:
      hadoop-net:
        ipv4_address: 172.25.0.6
    tty: true
    deploy:
      resources:
        limits:
          memory: 16G

  spark-worker-2:
    build: ./spark
    container_name: spark-worker-2
    ports:
      - "8082:8081"
      - "2227:22"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
    networks:
      hadoop-net:
        ipv4_address: 172.25.0.7
    tty: true
    deploy:
      resources:
        limits:
          memory: 16G

  spark-worker-3:
    build: ./spark
    container_name: spark-worker-3
    ports:
      - "8083:8081"
      - "2228:22"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
    networks:
      hadoop-net:
        ipv4_address: 172.25.0.8
    tty: true
    deploy:
      resources:
        limits:
          memory: 16G

  spark-worker-4:
    build: ./spark
    container_name: spark-worker-4
    ports:
      - "8084:8081"
      - "2229:22"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
    networks:
      hadoop-net:
        ipv4_address: 172.25.0.9
    tty: true
    deploy:
      resources:
        limits:
          memory: 16G

  spark-worker-5:
    build: ./spark
    container_name: spark-worker-5
    ports:
      - "8085:8081"
      - "2230:22"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
    networks:
      hadoop-net:
        ipv4_address: 172.25.0.10
    tty: true
    deploy:
      resources:
        limits:
          memory: 16G

networks:
  hadoop-net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.25.0.0/16

volumes:
  namenode-data:
  datanode1-data:
  datanode2-data:
